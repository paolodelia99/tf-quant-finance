{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EheA5_j_cEwc"
      },
      "source": [
        "##### Copyright 2019 Google LLC.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCriMWd-pRTP"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\"); { display-mode: \"form\" }\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvRwFTkqcp1e"
      },
      "source": [
        "# Introduction to TensorFlow Part 3 - Advanced Tensor Manipulation\n",
        "\n",
        "\u003ctable class=\"tfo-notebook-buttons\" align=\"left\"\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://colab.research.google.com/github/google/tf-quant-finance/blob/master/tf_quant_finance/examples/jupyter_notebooks/Introduction_to_TensorFlow.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /\u003eRun in Google Colab\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://github.com/paolodelia99/tf-quant-finance/blob/main/tf_quant_finance/examples/jupyter_notebooks/Introduction_to_TensorFlow.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /\u003eView source on GitHub\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "\u003c/table\u003e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "97ZM2JhA23pR"
      },
      "outputs": [],
      "source": [
        "#@title Upgrade to TensorFlow 2.5+\n",
        "!pip install --upgrade tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nPX9m7Q_w_8p"
      },
      "outputs": [],
      "source": [
        "#@title Install and import Libraries for this colab. RUN ME FIRST!\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obZHjPQScSqd"
      },
      "source": [
        "# What this notebook covers\n",
        "\n",
        "This notebook carries on from [part 2](https://colab.research.google.com/github/google/tf-quant-finance/blob/master/tf_quant_finance/examples/jupyter_notebooks/Introduction_to_TensorFlow_Part_2_-_Debugging_and_Control_Flow.ipynb\n",
        "), and covers various advanced ways of manipulating tensors, including\n",
        "*   Gather\n",
        "*   Updating tensor entries\n",
        "*   Sparse Tensors\n",
        "*   Various functional ops:\n",
        "    * tf.foldl \n",
        "    * tf.foldr\n",
        "    * tf.map_fn\n",
        "    * tf.vectorized_map\n",
        "\n",
        "* XLA compilation\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVLqCYzuDhfT"
      },
      "source": [
        "# Scatter / Gather"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_md9nF-EbCcn"
      },
      "source": [
        "## tf.gather_nd\n",
        "\n",
        "[Full documentation](https://www.tensorflow.org/api_docs/python/tf/gather_nd)\n",
        "\n",
        "This operation allows you to take a multi-dimensional tensor and extract a list of subsets of data from it, according to a list of indices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 57,
          "status": "ok",
          "timestamp": 1626699697972,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "z7nnDntT32V0",
        "outputId": "72ee0185-fc70-4339-d2a0-dc60bc41211d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking up [[1, 1, 1]] gives us\n",
            "tf.Tensor([222], shape=(1,), dtype=int32)\n",
            "\n",
            "Looking up [[1, 1, 1], [0, 0, 0], [0, 0, 1]] gives us\n",
            "tf.Tensor([222 111 112], shape=(3,), dtype=int32)\n",
            "\n",
            "Looking up [[0, 0]] gives us\n",
            "tf.Tensor([[111 112 113]], shape=(1, 3), dtype=int32)\n",
            "\n",
            "Looking up [[1]] gives us\n",
            "tf.Tensor(\n",
            "[[[211 212 213]\n",
            "  [221 222 223]\n",
            "  [231 232 233]]], shape=(1, 3, 3), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "source = tf.constant([[[111,112,113], [121,122,123], [131,132,133]], \n",
        "                      [[211,212,213], [221,222,223], [231,232,233]]])\n",
        "\n",
        "# if we specify all values for all of source's dimensions, then we get a \n",
        "# single value\n",
        "indices = [[1,1,1]]\n",
        "print(\"Looking up %s gives us\\n%s\" %(\n",
        "    indices, tf.gather_nd(source, indices)))\n",
        "\n",
        "# we can look up multiple sets of indices\n",
        "indices = [[1,1,1], [0,0,0], [0,0,1]]\n",
        "print(\"\\nLooking up %s gives us\\n%s\" %(\n",
        "    indices, tf.gather_nd(source, indices)))\n",
        "\n",
        "# if we don't specify values for all of source's dimensions, then we get \n",
        "# results of larger shape\n",
        "indices = [[0,0]]\n",
        "print(\"\\nLooking up %s gives us\\n%s\" %(\n",
        "    indices, tf.gather_nd(source, indices)))  \n",
        "indices = [[1]]\n",
        "print(\"\\nLooking up %s gives us\\n%s\" %(\n",
        "    indices, tf.gather_nd(source, indices)))    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9B9cza9zD4Iw"
      },
      "source": [
        "The indices can easily be generated with tf.where:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 57,
          "status": "ok",
          "timestamp": 1626699699190,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "npOjtvGYECW1",
        "outputId": "d6983f5c-05cd-4385-9c06-cf9338ade8e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([111 123 132 213 222 231], shape=(6,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "source = tf.constant([[[111,112,113], [121,122,123], [131,132,133]], \n",
        "                      [[211,212,213], [221,222,223], [231,232,233]]])\n",
        "values_divisible_by_three = tf.gather_nd(\n",
        "    source, tf.where(tf.equal(0, source % 3)))\n",
        "\n",
        "print(values_divisible_by_three)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tC0kpUqv6GBB"
      },
      "source": [
        "## Updating elements of a Tensor\n",
        "\n",
        "Tensors are immutable objects. Often there is a need to update certain values of a Tensor. In order to achieve this, one can use `tf.tensor_scatter_nd`, which creates a copy of the input Tensor along with updated values at the specified indices.\n",
        "\n",
        "For user convenience a number of similar methods are available, such as `tf.tensor_scatter_nd_add/sub/min/max`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 91,
          "status": "ok",
          "timestamp": 1626770995977,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "12TanrDqG0PH",
        "outputId": "8cbba37b-663d-4ec6-d337-a8309316be5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Tensor:\n",
            "tf.Tensor(\n",
            "[[[ 1  2  3]\n",
            "  [ 4  5  6]\n",
            "  [ 7  8  9]]\n",
            "\n",
            " [[11 12 13]\n",
            "  [14 15 16]\n",
            "  [17 18 19]]], shape=(2, 3, 3), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "x = tf.constant([[[1, 2, 3], [4, 5, 6], [7, 8, 9]],\n",
        "                [[11, 12, 13], [14, 15, 16], [17, 18, 19]]])\n",
        "# Original Tensor\n",
        "print(\"Original Tensor:\\n%s\"%x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 73,
          "status": "ok",
          "timestamp": 1626771090419,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "JVXqOUzMElX5",
        "outputId": "9cdbc4cf-1ad3-4f3e-a790-cd101b7c7bb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updating a single single value:\n",
            "tf.Tensor(\n",
            "[[[ 1  2  3]\n",
            "  [ 4  5 -1]\n",
            "  [ 7  8  9]]\n",
            "\n",
            " [[11 12 13]\n",
            "  [14 15 16]\n",
            "  [17 18 19]]], shape=(2, 3, 3), dtype=int32)\n",
            "\n",
            "Updating multiple values:\n",
            "tf.Tensor(\n",
            "[[[-1  2  3]\n",
            "  [ 4 -2  6]\n",
            "  [ 7  8 -3]]\n",
            "\n",
            " [[11 12 13]\n",
            "  [14 15 16]\n",
            "  [17 18 19]]], shape=(2, 3, 3), dtype=int32)\n",
            "\n",
            "Scattering entire rows:\n",
            "tf.Tensor(\n",
            "[[[-1 -2 -3]\n",
            "  [-4 -5 -6]\n",
            "  [ 7  8  9]]\n",
            "\n",
            " [[11 12 13]\n",
            "  [14 15 16]\n",
            "  [17 18 19]]], shape=(2, 3, 3), dtype=int32)\n",
            "\n",
            "Updating the entire matrix:\n",
            "tf.Tensor(\n",
            "[[[-1 -2 -3]\n",
            "  [-4 -5 -6]\n",
            "  [-7 -8 -9]]\n",
            "\n",
            " [[11 12 13]\n",
            "  [14 15 16]\n",
            "  [17 18 19]]], shape=(2, 3, 3), dtype=int32)\n",
            "\n",
            "Updating single value multiple times:\n",
            "tf.Tensor(\n",
            "[[[-3  2  3]\n",
            "  [ 4  5  6]\n",
            "  [ 7  8  9]]\n",
            "\n",
            " [[11 12 13]\n",
            "  [14 15 16]\n",
            "  [17 18 19]]], shape=(2, 3, 3), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "print(\"Updating a single single value:\\n%s\"%\n",
        "      tf.tensor_scatter_nd_update(\n",
        "          x,\n",
        "          indices = [[0, 1, 2]],\n",
        "          updates = [-1]))\n",
        "\n",
        "print(\"\\nUpdating multiple values:\\n%s\"%\n",
        "      tf.tensor_scatter_nd_update(\n",
        "          x,\n",
        "          indices = [[0, 0, 0], [0, 1, 1], [0, 2, 2]], \n",
        "          updates = [-1, -2, -3]))\n",
        "\n",
        "# You can reduce the dimensions of indices and increase the dimensions of \n",
        "# updates\n",
        "print(\"\\nScattering entire rows:\\n%s\"%\n",
        "      tf.tensor_scatter_nd_update(\n",
        "          x,\n",
        "          indices = [[0,0], [0,1]], \n",
        "          updates = [[-1, -2, -3], [-4, -5,- 6]]))\n",
        "\n",
        "print(\"\\nUpdating the entire matrix:\\n%s\"%\n",
        "      tf.tensor_scatter_nd_update(\n",
        "          x,\n",
        "          indices = [[0]], \n",
        "          updates = [[[-1, -2, -3], [-4, -5, -6], [-7, -8, -9]]]))\n",
        "\n",
        "# Note that if `indices` contains duplicate or overlapping values, then the \n",
        "# clashing updates will be added together (in an indeterminate order, which \n",
        "# may result in non-deterministic output in the case of multiple floating \n",
        "# point values of wildly different sizes).\n",
        "print(\"\\nUpdating single value multiple times:\\n%s\"%\n",
        "      tf.tensor_scatter_nd_update(\n",
        "          x,\n",
        "          indices = [[0,0,0], [0,0,0], [0,0,0]], \n",
        "          updates = [-1, -2, -3]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfNajZEZG3sd"
      },
      "source": [
        "##tf.scatter_nd\n",
        "[Full documentation](https://www.tensorflow.org/api_docs/python/tf/scatter_nd)\n",
        "\n",
        "`scatter_nd` is similar to `tf.tensor_scatter_nd_update`. It creates a zero-initialised tensor of a given shape, and then writes a series of specified values at specified positions in that tensor.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYiOe3ZsT05b"
      },
      "source": [
        "### Gather then Update\n",
        "In some cases, you will want `tensor_scatter_nd` to act as a \"setter\" to `gather_nd`'s \"getter\": i.e. you have a tensor, you extract a subset of values that meet a certain criteria using `gather_nd`, you calculate new values for that subset, and then create a new tensor based on the original that replaces the elements that met the criteria with the new values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 72,
          "status": "ok",
          "timestamp": 1626704747035,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "gbpQx-xrU707",
        "outputId": "6e406532-cdb3-45c6-e6b2-51f73b417dd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[ 11 112 113]\n",
            "  [121 122  23]\n",
            "  [131  32 133]]\n",
            "\n",
            " [[211 212  13]\n",
            "  [221  22 223]\n",
            "  [ 31 232 233]]], shape=(2, 3, 3), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "source = tf.constant([[[111,112,113], [121,122,123], [131,132,133]], \n",
        "                      [[211,212,213], [221,222,223], [231,232,233]]])\n",
        "# Create a list of indices where is_divisible_by_three is true (we no longer \n",
        "# need the to keep a reference to the result of tf.equal)\n",
        "indices = tf.where(tf.equal(0, source % 3))\n",
        "# Extract a list of values that need updating\n",
        "values_divisible_by_three = tf.gather_nd(source, indices)\n",
        "# Perform a really expensive operation on those values\n",
        "new_values = values_divisible_by_three % 100\n",
        "# Update entries in the original Tensor\n",
        "new_tensor = tf.tensor_scatter_nd_update(\n",
        "    source, indices, new_values)\n",
        "# Updated Tensor\n",
        "print(new_tensor)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOqSOkTAH9No"
      },
      "source": [
        "## Exercise: Mandlebrot set\n",
        "\n",
        "Lets revisit the Mandlebrot set from the previous training course. In that solution, we ran the z=z*z+c calculation for all co-ordinates, even the ones whose magnitude had already gone over 2.\n",
        "\n",
        "For the purpose of this exercise, we will pretend that the complex calculation is very expensive and that we should eliminate the calculation where possible. In actual fact, the calculation is utterly trivial and swamped by the cost of the gather/scatter operations, but the same methods can be used in situations rather more expensive than a complex add and multiply"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZZxF2l0it9-"
      },
      "outputs": [],
      "source": [
        "MAX_ITERATIONS = 64\n",
        "NUM_PIXELS = 512\n",
        "\n",
        "def generate_grid(nX, nY, bottom_left=(-1.0, -1.0), top_right=(1.0, 1.0)):\n",
        "  \"\"\"Generates a complex matrix of shape [nX, nY].\n",
        "  \n",
        "  Generates an evenly spaced grid of complex numbers spanning the rectangle \n",
        "  between the supplied diagonal points. \n",
        "  \n",
        "  Args:\n",
        "    nX: A positive integer. The number of points in the horizontal direction.\n",
        "    nY: A positive integer. The number of points in the vertical direction.\n",
        "    bottom_left: The coordinates of the bottom left corner of the rectangle to\n",
        "      cover.\n",
        "    top_right: The coordinates of the top right corner of the rectangle to\n",
        "      cover.\n",
        "\n",
        "  Returns:\n",
        "    A constant tensor of type complex64 and shape [nX, nY].\n",
        "  \"\"\"\n",
        "  x = tf.linspace(bottom_left[0], top_right[0], nX)\n",
        "  y = tf.linspace(bottom_left[1], top_right[1], nY)\n",
        "  real, imag = tf.meshgrid(x, y)\n",
        "  return tf.cast(tf.complex(real, imag), tf.complex128)\n",
        "\n",
        "c_values = generate_grid(NUM_PIXELS, NUM_PIXELS)\n",
        "initial_Z_values = tf.zeros_like(c_values, dtype=tf.complex128)\n",
        "initial_diverged_after = tf.ones_like(c_values, dtype=tf.int32) * MAX_ITERATIONS\n",
        "\n",
        "# You need to put the various values you want to change inside the loop here\n",
        "loop_vars = (0, initial_Z_values, initial_diverged_after)\n",
        "\n",
        "# this needs to take the same number of arguments as loop_vars contains and\n",
        "# return a tuple of equal size with the next iteration's values\n",
        "def body(iteration_count, Z_values, diverged_after):\n",
        "  # a matrix of bools showing all the co-ordinatesthat haven't diverged yet\n",
        "  not_diverged = tf.equal(diverged_after, MAX_ITERATIONS)\n",
        "  # a list of the indices in not_diverged that are true\n",
        "  not_diverged_indices = tf.where(not_diverged)\n",
        "\n",
        "  # you now need to gather just the Z and c values covered by \n",
        "  # not_diverged_indices, calculate the new Z values, and then scatter the \n",
        "  # values back into a new Z_values matrix to pass to the next iteration.\n",
        "\n",
        "  new_Z_values = # TODO\n",
        "\n",
        "  # And now we're back to the original code\n",
        "  has_diverged = tf.abs(new_Z_values) \u003e 2.0\n",
        "  new_diverged_after = tf.minimum(diverged_after, tf.where(\n",
        "      has_diverged, iteration_count, MAX_ITERATIONS))\n",
        "\n",
        "  return (iteration_count+1, new_Z_values, new_diverged_after)\n",
        "\n",
        "# this just needs to take the same number of arguments as loop_vars contains and\n",
        "# return true (we'll use maximum_iterations to exit the loop)\n",
        "def cond(iteration_count, Z_values, diverged_after):\n",
        "  return True\n",
        "\n",
        "results = tf.while_loop(\n",
        "    loop_vars=loop_vars, \n",
        "    body = body, \n",
        "    cond = cond, \n",
        "    maximum_iterations=MAX_ITERATIONS)\n",
        "\n",
        "\n",
        "## extract the final value of diverged_after from the tuple\n",
        "final_diverged_after = results[-1]\n",
        "plt.matshow(final_diverged_after)\n",
        "pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "colab": {
          "height": 275
        },
        "executionInfo": {
          "elapsed": 1154,
          "status": "ok",
          "timestamp": 1626704754941,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "JSitXn3PyIIe",
        "outputId": "60739cf2-032c-4276-bfbd-0a0116fcafe6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQwAAAECCAYAAAALhunjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\nYWGRMf8/vlzJ9PJtIhQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "\u003cFigure size 400x400 with 1 Axes\u003e"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title Solution: Mandlebrot set (Double-click to reveal)\n",
        "\n",
        "MAX_ITERATIONS = 64\n",
        "NUM_PIXELS = 512\n",
        "\n",
        "def GenerateGrid(nX, nY, bottom_left=(-1.0, -1.0), top_right=(1.0, 1.0)):\n",
        "  \"\"\"Generates a complex matrix of shape [nX, nY].\n",
        "  \n",
        "  Generates an evenly spaced grid of complex numbers spanning the rectangle \n",
        "  between the supplied diagonal points. \n",
        "  \n",
        "  Args:\n",
        "    nX: A positive integer. The number of points in the horizontal direction.\n",
        "    nY: A positive integer. The number of points in the vertical direction.\n",
        "    bottom_left: The coordinates of the bottom left corner of the rectangle to\n",
        "      cover.\n",
        "    top_right: The coordinates of the top right corner of the rectangle to\n",
        "      cover.\n",
        "\n",
        "  Returns:\n",
        "    A constant tensor of type complex64 and shape [nX, nY].\n",
        "  \"\"\"\n",
        "  x = tf.linspace(bottom_left[0], top_right[0], nX)\n",
        "  y = tf.linspace(bottom_left[1], top_right[1], nY)\n",
        "  real, imag = tf.meshgrid(x, y)\n",
        "  return tf.cast(tf.complex(real, imag), tf.complex128)\n",
        "\n",
        "c_values = GenerateGrid(NUM_PIXELS, NUM_PIXELS)\n",
        "initial_Z_values = tf.zeros_like(c_values, dtype=tf.complex128)\n",
        "initial_diverged_after = tf.ones_like(c_values, dtype=tf.int32) * MAX_ITERATIONS\n",
        "\n",
        "# You need to put the various values you want to change inside the loop here\n",
        "loop_vars = (0, initial_Z_values, initial_diverged_after)\n",
        "\n",
        "# this needs to take the same number of arguments as loop_vars contains and\n",
        "# return a tuple of equal size with the next iteration's values\n",
        "def body(iteration_count, Z_values, diverged_after):\n",
        "  # a matrix of bools showing all the co-ordinatesthat haven't diverged yet\n",
        "  not_diverged = tf.equal(diverged_after, MAX_ITERATIONS)\n",
        "  # a list of the indices in not_diverged that are true\n",
        "  not_diverged_indices = tf.where(not_diverged)\n",
        "\n",
        "  # Gather the values for just the undiverged co-ordinates, and generate the \n",
        "  # next iteration's values\n",
        "  not_diverged_c_values_array = tf.gather_nd(c_values, not_diverged_indices)\n",
        "  not_diverged_Z_values_array = tf.gather_nd(Z_values, not_diverged_indices)\n",
        "  new_Z_values_array = (not_diverged_Z_values_array * not_diverged_Z_values_array\n",
        "                        + not_diverged_c_values_array)\n",
        "  \n",
        "  # merge the new values with the already-diverged\n",
        "  new_Z_values_or_zeroes = tf.scatter_nd(\n",
        "      not_diverged_indices, \n",
        "      new_Z_values_array, \n",
        "      tf.shape(Z_values, out_type=tf.dtypes.int64))\n",
        "  new_Z_values = tf.where(not_diverged, new_Z_values_or_zeroes, Z_values)\n",
        "\n",
        "  # And now we're back to the original code\n",
        "  has_diverged = tf.abs(new_Z_values) \u003e 2.0\n",
        "  new_diverged_after = tf.minimum(diverged_after, tf.where(\n",
        "      has_diverged, iteration_count, MAX_ITERATIONS))\n",
        "  return (iteration_count+1, new_Z_values, new_diverged_after)\n",
        "\n",
        "# this just needs to take the same number of arguments as loop_vars contains and\n",
        "# return true (we'll use maximum_iterations to exit the loop)\n",
        "def cond(iteration_count, Z_values, diverged_after):\n",
        "  return True\n",
        "\n",
        "results = tf.while_loop(\n",
        "    loop_vars=loop_vars, \n",
        "    body = body, \n",
        "    cond = cond, \n",
        "    maximum_iterations=MAX_ITERATIONS)\n",
        "\n",
        "## extract the final value of diverged_after from the tuple\n",
        "final_diverged_after = results[-1]\n",
        "plt.matshow(final_diverged_after)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAlaMKj0gZdX"
      },
      "source": [
        "## SparseTensor\n",
        "\n",
        "[Full documentation](https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor])\n",
        "\n",
        "A sparse tensor is created from a list of indices, a list of values and a shape: the same as the arguments to scatter_nd. Any element within the tensor that doesn't have an explicit value will be treated as zero. So a sparse tensor can be viewed as a deferred call to scatter_nd.\n",
        "\n",
        "For large tensors where most of the values are zero, sparse tensors can grant major savings in memory. The [tf.sparse module](https://www.tensorflow.org/api_docs/python/tf/sparse) contains several specialised operations that know how to work with sparse tensor's internals and skipping all the zero values, thus granting major savings in processing speed as well.\n",
        "\n",
        "Similarly sparse tensors can be efficiently divided or multiplied by a tensor or scalar. But attempts to perform inefficient operations on a sparse tensor (i.e. ones likely to set most elements to a non-zero value) are not allowed. You need to convert the sparse tensor to a normal, or \"dense\", tensor with the ```tf.sparse.to_dense``` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 60,
          "status": "ok",
          "timestamp": 1626704763813,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "qDJmkGN2lBhB",
        "outputId": "84bf6a27-5a9f-462c-aa60-0b2955ae822f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sparse =\n",
            "SparseTensor(indices=tf.Tensor(\n",
            "[[0 0 0]\n",
            " [0 1 2]\n",
            " [0 2 1]\n",
            " [1 0 2]\n",
            " [1 1 1]\n",
            " [1 2 0]], shape=(6, 3), dtype=int64), values=tf.Tensor([111 123 132 213 222 231], shape=(6,), dtype=int32), dense_shape=tf.Tensor([2 3 3], shape=(3,), dtype=int64))\n",
            "\n",
            "sparse * dense =\n",
            "SparseTensor(indices=tf.Tensor(\n",
            "[[0 0 0]\n",
            " [0 1 2]\n",
            " [0 2 1]\n",
            " [1 0 2]\n",
            " [1 1 1]\n",
            " [1 2 0]], shape=(6, 3), dtype=int64), values=tf.Tensor([12321 15129 17424 45369 49284 53361], shape=(6,), dtype=int32), dense_shape=tf.Tensor([2 3 3], shape=(3,), dtype=int64))\n",
            "\n",
            "dense * sparse\n",
            "SparseTensor(indices=tf.Tensor(\n",
            "[[0 0 0]\n",
            " [0 1 2]\n",
            " [0 2 1]\n",
            " [1 0 2]\n",
            " [1 1 1]\n",
            " [1 2 0]], shape=(6, 3), dtype=int64), values=tf.Tensor([12321 15129 17424 45369 49284 53361], shape=(6,), dtype=int32), dense_shape=tf.Tensor([2 3 3], shape=(3,), dtype=int64))\n",
            "\n",
            "sparse / dense\n",
            "SparseTensor(indices=tf.Tensor(\n",
            "[[0 0 0]\n",
            " [0 1 2]\n",
            " [0 2 1]\n",
            " [1 0 2]\n",
            " [1 1 1]\n",
            " [1 2 0]], shape=(6, 3), dtype=int64), values=tf.Tensor([1. 1. 1. 1. 1. 1.], shape=(6,), dtype=float64), dense_shape=tf.Tensor([2 3 3], shape=(3,), dtype=int64))\n",
            "\n",
            "to_dense gives\n",
            "tf.Tensor(\n",
            "[[[111   0   0]\n",
            "  [  0   0 123]\n",
            "  [  0 132   0]]\n",
            "\n",
            " [[  0   0 213]\n",
            "  [  0 222   0]\n",
            "  [231   0   0]]], shape=(2, 3, 3), dtype=int32)\n",
            "\n",
            "scatter_nd gives\n",
            "tf.Tensor(\n",
            "[[[111   0   0]\n",
            "  [  0   0 123]\n",
            "  [  0 132   0]]\n",
            "\n",
            " [[  0   0 213]\n",
            "  [  0 222   0]\n",
            "  [231   0   0]]], shape=(2, 3, 3), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "source = tf.constant([[[111,112,113], [121,122,123], [131,132,133]], \n",
        "                      [[211,212,213], [221,222,223], [231,232,233]]])\n",
        "# create a list of indices where is_divisible_by_three is true\n",
        "indices = tf.where(tf.equal(0, source % 3))\n",
        "# extract a matching list of values\n",
        "values_divisible_by_three = tf.gather_nd(source, indices)\n",
        "\n",
        "sparse = tf.sparse.SparseTensor(\n",
        "    indices, \n",
        "    values_divisible_by_three, \n",
        "    tf.shape(source, out_type=tf.dtypes.int64))\n",
        "print (\"sparse =\")\n",
        "print(sparse)\n",
        "# We can efficiently multiply sparse by a dense tensor\n",
        "print (\"\\nsparse * dense =\")\n",
        "print(sparse * source)\n",
        "# We can efficiently multiply a dense tensor by a sparse\n",
        "print (\"\\ndense * sparse\")\n",
        "print(source * sparse)\n",
        "# We can efficiently divide sparse by a dense tensor\n",
        "print (\"\\nsparse / dense\")\n",
        "print(sparse / source)\n",
        "\n",
        "# But attempts to perform inefficient operations on a sparse tensor (i.e. ones\n",
        "# likely to set most elements to a non-zero value) are not allowed.\n",
        "# You need to convert the sparse tensor into a dense tensor first.\n",
        "try:\n",
        "  not_allowed = sparse + source\n",
        "except ValueError:\n",
        "  pass\n",
        "\n",
        "# Running to_dense is exactly the same as calling scatter_nd:\n",
        "print (\"\\nto_dense gives\")\n",
        "print(tf.sparse.to_dense(sparse))\n",
        "print (\"\\nscatter_nd gives\")\n",
        "print(tf.scatter_nd(sparse.indices, sparse.values, sparse.dense_shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Afi0jfqkI9as"
      },
      "source": [
        "# Functional ops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAVQxV71JF59"
      },
      "source": [
        "## tf.foldl and tf.foldr\n",
        "\n",
        "[Full documentation](https://www.tensorflow.org/api_docs/python/tf/foldl)\n",
        "\n",
        "These two functions split a given tensor across its first dimension. The resulting subtensors are then each passed to an op along with an \"accumulator\". \n",
        "For most iterations, the value of the accumulator will be the result of the previous iteration. But for the first iteration, the accumulator will either be passed an initial value passed into the foldl/foldr call, or the first subtensor. The final iteration's result then becomes the overall result of the op.\n",
        "\n",
        "So the rough pseudo code of ```x = tf.foldl(op, [[1,1], [2,2], [3,3]], initializer)``` would be\n",
        "``` python\n",
        "result_iteration1 = op(initializer, [1,1])\n",
        "result_iteration2 = op(result_iteration1, [2,2])\n",
        "result iteration3 = op(result_iteration2, [3,3])\n",
        "x = result_iteration3\n",
        "```\n",
        "Whereas the rough pseudo-code of  ```x = tf.foldl(op, [[1,1], [2,2], [3,3])``` (i.e. no initializer supplied) would be\n",
        "``` python\n",
        "result_iteration1 = op([1,1]], [2,2])\n",
        "result_iteration2 = op(result_iteration1, [3,3])\n",
        "x = result_iteration3\n",
        "```\n",
        "\n",
        "```foldr``` is identical to ```foldl```, except that the order the tensor is iterated through is reversed. So the rough pseudo code of ```x = tf.foldr(op, [[1,1], [2,2], [3,3], initializer)``` would be\n",
        "``` python\n",
        "result_iteration1 = op(initializer, [3,3])\n",
        "result_iteration2 = op(result_iteration1, [2,2])\n",
        "result iteration3 = op(result_iteration2, [1,1])\n",
        "x = result_iteration3\n",
        "```\n",
        "\n",
        "The only complication of this method is that the op is defined by a python callable. Note that the callable is only called once, at execution time, to build the operation. **Your python callable is not called for every row in the input**, nor can it see the individual values. It is the op created by your python code that will be repeatedly called. \n",
        "\n",
        "Note that despite this, use of these methods still eliminates several optimisation opportunities that are present in tensorflow built-in operations. So if you can use something like `tf.math.reduce_sum` instead of these ops then your code may well run significantly faster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 143,
          "status": "ok",
          "timestamp": 1626704828546,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "40cDr4ogOk8W",
        "outputId": "ae16f080-4599-46ff-d438-0693555623c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing foldl\n",
            "In my_function.\n",
            "foldl result:\n",
            "tf.Tensor([ 9 12], shape=(2,), dtype=int32)\n",
            "\n",
            "Executing foldr\n",
            "foldr result:\n",
            "tf.Tensor([20 24], shape=(2,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "source = tf.constant([[1,2],[3,4],[5,6]])\n",
        "\n",
        "# element\n",
        "@tf.function\n",
        "def my_function(previous_iterations_result, element):\n",
        "  print(\"In my_function.\")\n",
        "  # this depends on the previous values, thus highlighting the difference \n",
        "  # between foldl and foldr\n",
        "  return tf.math.maximum(\n",
        "      previous_iterations_result, element) + previous_iterations_result\n",
        "\n",
        "print(\"Executing foldl\")\n",
        "print(\"foldl result:\\n%s\"%\n",
        "      tf.foldl(my_function, source))\n",
        "\n",
        "print(\"\\nExecuting foldr\")\n",
        "print(\"foldr result:\\n%s\"%\n",
        "      tf.foldr(my_function, source))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9xLy92GtXHx"
      },
      "source": [
        "## tf.map_fn\n",
        "\n",
        "This op is similar to `foldl`, but the python function only takes a single argument, it lacks the accumulator argument containing the result of the previous iteration. Again the callable is called just once, and is used to generate an tensorflow op. It is this generated op that is executed once per row. And again, be aware that replacing the map_fn call with a built-in op - if possible - can result in significant increases in speed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 121,
          "status": "ok",
          "timestamp": 1626704833294,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "x4CPdY9bzhjs",
        "outputId": "0a9ce7b1-4ee5-4c62-b199-25871040f3e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In my_function\n",
            "foldr result:\n",
            "tf.Tensor([ 3  7 11], shape=(3,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "source = tf.constant([[1,2],[3,4],[5,6]])\n",
        "\n",
        "# element \n",
        "@tf.function\n",
        "def my_function(element):\n",
        "  print(\"In my_function\")  \n",
        "  return tf.math.reduce_sum(element)\n",
        "\n",
        "\n",
        "print(\"foldr result:\\n%s\"%\n",
        "      tf.map_fn(my_function, source))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDmSuHp0uogc"
      },
      "source": [
        "## tf.vectrorized_map\n",
        "\n",
        "This op is similar to `map_fn`, but has a much better performance due to vectorization. `map_fn` is serial since it is based on `tf.while_loop`, while `tf.vectorized_map` relies on [`pfor`](https://github.com/tensorflow/tensorflow/blob/a4dfb8d1a71385bd6d122e4f27f86dcebb96712d/tensorflow/python/ops/parallel_for/control_flow_ops.py#L546) (parallel for) in its implementation. Potential speed can be the same as from batching.\n",
        "\n",
        "The op is useful to parallelize tasks where batching is hard to achieve (e.g., Jacobian calculation).\n",
        "\n",
        "See [official documentation](https://www.tensorflow.org/api_docs/python/tf/vectorized_map) for more details.\n",
        "\n",
        "Again the callable is called just once, and is used to generate a tensorflow op."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 95,
          "status": "ok",
          "timestamp": 1626699722723,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "EC1VO2Ncuogh",
        "outputId": "2f38dd53-e28e-4fd2-dc79-dac6ffe58d9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In my_function\n",
            "foldr result:\n",
            "tf.Tensor([ 3  7 11], shape=(3,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "source = tf.constant([[1,2],[3,4],[5,6]])\n",
        "\n",
        "# element \n",
        "@tf.function\n",
        "def my_function(element):\n",
        "  print(\"In my_function\")\n",
        "  return tf.math.reduce_sum(element)\n",
        "\n",
        "\n",
        "print(\"foldr result:\\n%s\"%\n",
        "      tf.vectorized_map(my_function, source))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hy6I3Es4u-we"
      },
      "outputs": [],
      "source": [
        "# Vectorization map vs map_fn vs batching\n",
        "\n",
        "@tf.function\n",
        "def square_map(x):\n",
        "  return tf.map_fn(lambda x: x**2, x)\n",
        "\n",
        "@tf.function\n",
        "def square_vectorized_map(x):\n",
        "  return tf.vectorized_map(lambda x: x**2, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BZorlzkyDK5"
      },
      "outputs": [],
      "source": [
        "dtype = tf.float64\n",
        "x = tf.random.uniform([1_000], dtype=dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEITS8Ak49Ce"
      },
      "source": [
        "When timing, we call `.numpy()` to ensure the result is copied to memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 5832,
          "status": "ok",
          "timestamp": 1626700283301,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "tGg8ogP9x-Oz",
        "outputId": "dfcac3af-e687-4bdf-89b6-b6f4cea5693a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100 loops, best of 5: 9.01 ms per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "# map_fn speed\n",
        "square_map(x).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 1296,
          "status": "ok",
          "timestamp": 1626700286086,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "AVCu7bDbyHb7",
        "outputId": "41c365a1-0cbf-4862-8849-5d6ad4c25ffa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1000 loops, best of 5: 173 µs per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "# vectorized_map speed\n",
        "square_vectorized_map(x).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 7660,
          "status": "ok",
          "timestamp": 1626700302068,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "72D6nsYFygaR",
        "outputId": "41165ddb-f693-432b-8ca4-d4c7a3cf2e22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10000 loops, best of 5: 123 µs per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "# Batched version\n",
        "(x**2).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhjYUTsey4pY"
      },
      "source": [
        "# XLA compilation\n",
        "\n",
        "One of the main TensorFlow concepts is computational graph. One can imagine that knowing the graph should provide enough information to create an efficient low-level code targeting a specific device (i.e., CPU/GPU/TPU). XLA (Accelerated Linear Algebra) is a compiler that does precisely that - it creates an LLVM representation from the computational graph, potentially brinning significant speed up to the calculation. Compilation can be done in either Ahead-of-time (AOT) or Just-in-time (JIT) modes.\n",
        "\n",
        "Refer to the [official XLA page](https://www.tensorflow.org/xla) for more details. XLA Architecture details can be found [here](https://www.tensorflow.org/xla/architecture).\n",
        "\n",
        "From user perspective, using JIT compilation is easy: simply set `jit_compile=True` argument of `tf.function`. \n",
        "\n",
        "To use AOT compilation mode please refer to the [documentation](https://www.tensorflow.org/xla/tfcompile).\n",
        "\n",
        "\n",
        "**NB**  \n",
        "  * At the moment not every function can be XLA-compiled. For example, inputs and output shapes of `tf.while_loop` should be the same. Also, some of the ops might be missing an XLA implementation.\n",
        "  * JIT-compilation means that compilation happens at the first function call. For the successive calls, the compiled function is used. If an input has a different shape from the one used during the compilation, JIT-compilation happens again for the new input shapes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_FrtMsbyZxe"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def square_map(x):\n",
        "  return tf.map_fn(lambda x: x**2, x)\n",
        "\n",
        "@tf.function(jit_compile=True)\n",
        "def square_map_xla(x):\n",
        "  return tf.map_fn(lambda x: x**2, x)\n",
        "\n",
        "@tf.function(jit_compile=True)\n",
        "def square_vectorized_map_xla(x):\n",
        "  return tf.vectorized_map(lambda x: x**2, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLaIYwn1zCpt"
      },
      "outputs": [],
      "source": [
        "dtype = tf.float64\n",
        "x = tf.random.uniform([1_000], dtype=dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 5905,
          "status": "ok",
          "timestamp": 1626700312542,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "03MKsonR3MkX",
        "outputId": "373f0e23-1f20-4ab3-8d09-5b52fe8ae85d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100 loops, best of 5: 9 ms per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "square_map(x).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 1739,
          "status": "ok",
          "timestamp": 1626700314386,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "1-KFhv54y9aU",
        "outputId": "2b855595-040d-409a-fec1-f3cc4c84c394"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1000 loops, best of 5: 228 µs per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "# Compare time to the non-compiled code above\n",
        "square_map_xla(x).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63j4Vq5D3pQb"
      },
      "outputs": [],
      "source": [
        "# Now compare with compiled vectorized_map\n",
        "x = tf.random.uniform([500_000], dtype=dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 1768,
          "status": "ok",
          "timestamp": 1626700316400,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "QwYrCckE3yjp",
        "outputId": "a6efbe79-ccc2-4e83-f938-2fbc5d7588c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100 loops, best of 5: 2.67 ms per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "# map_fn + XLA\n",
        "square_map_xla(x).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 6423,
          "status": "ok",
          "timestamp": 1626700445657,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "B4ZFsAtt3zIB",
        "outputId": "f2649b64-c697-44a6-cb88-09a29bd987c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1000 loops, best of 5: 999 µs per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "# vectorized_map + XLA\n",
        "square_vectorized_map(x).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZyI_s_S5xE9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "//learning/deepmind/public/tools/ml_python:ml_notebook",
        "kind": "private"
      },
      "name": "Introduction_to_TensorFlow_Part_3_-_Advanced_Tensor_Manipulation.ipynb",
      "provenance": [
        {
          "file_id": "11mikyGawc9mOOVIXZENnm7TyFyyDyByB",
          "timestamp": 1568382156239
        }
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
